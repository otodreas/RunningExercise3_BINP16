import os
import pandas as pd
import numpy as np


os.chdir("../../tests/geneticdata")
files = os.listdir()
for i, f in enumerate(files):
    print(i, f)


input_file = files[4]
chromo_name = "mtDNA"
output_file = "output_file.tsv"

with open(input_file, "rb") as f:
    i = 0
    chromo_line = None
    data_list = []
    while True:
        line_b = f.readline()
        line = str(line_b)
        if chromo_name in line:
            chromo_line = i + 1
        if i == chromo_line:
            data_list.append(line[2:line.find("\\")])
        i += 1
        if not line_b:
            break

data = np.array(data_list)

seq_lens = []
for seq in data:
    seq_lens.append(len(seq))
    
if len(np.unique(seq_lens)) > 1:
    # TODO: throw error
    pass
else:
    positions = seq_lens[0]

with open(output_file, "w") as f:
    f.write("\t".join(output_header) + "\n")
    
for p in range(positions):
    nucleotides = []
    for seq in data:
        if seq[p].upper() in "ACGT":
            nucleotides.append(seq[p].upper())
    if nucleotides.count(nucleotides[0]) < len(nucleotides):
        alleles = set(nucleotides)
        freqs = {}
        for a in alleles:
            freqs[a] = nucleotides.count(a)
        ma = max(freqs, key=freqs.get)
        mi = min(freqs, key=freqs.get)
        maf = freqs[mi] / sum(freqs[a] for a in alleles)
        row = "\t".join([chromo_name, str(p), "/".join(alleles), str(ma), str(mi), str(round(maf, 2))]) + "\n"
        with open(output_file, "a") as f:
            f.write(row)


x = [1, 1, 1, 2]
x = set(x)
print(len(x))


x = "A/AaaaaaA/Aa"
i = len(x) - x[::-1].find("/")
print(x[i:])
print(os.getcwd())


x = {'A': 10, 'B': 3, 'C': 3}
ma = max(x, key=x.get)
mi = min(x, key=x.get)
print(ma, mi)
print(list(x.values()).count(min(x.values())))
#for val in [ma, mi]:
    #key = x.get(val)
 #   print(key)


x = {'A': 10, 'B': 3, 'C': 3}
ma = max(x, key=x.get)
mi = min(x, key=x.get)

import random

ma = []
mi = []
for item in x.items():
    if item[1] == min(list(x.values())):
        mi.append(item[0])
    elif item[1] == max(list(x.values())):
        ma.append(item[0])
ma = random.choice(ma)
mi = random.choice(mi)


random.seed(0)
print(type(random.choice(['B'])))


x = ['a', 'b', 'c']
popper = 'd'
x.pop(x.index(popper)) if popper in x else x
print(x)





i = 1
for _ in range(5):
    i *= 2
    print(i)


import numpy as np
import pandas as pd

np.random.seed(0)
d = np.eye(4)

scaler = 1
for i, row in enumerate(d):
    for j, col in enumerate(row):
        if i < j:
            scaler *= 1.5
            d[i][j] = abs(np.random.normal(loc=d[i][j], scale=0.5*scaler))
        else:
            d[i][j] = d[j][i]
d


# Load the Iris dataset
iris = load_iris()

# Access the features and target variable
X = iris.data  # Features (sepal length, sepal width, petal length, petal width)
y = iris.target  # Target variable (species: 0 for setosa, 1 for versicolor, 2 for virginica)

# Print the feature names and target names
print("Feature names:", iris.feature_names)
print("Target names:", iris.target_names)

# Print the first few samples in the dataset
print("First 5 samples:")
for i in range(5):
    print(f"Sample {i+1}: {X[i]} (Class: {y[i]}, Species: {iris.target_names[y[i]]})")
help(iris)


# exact copy of code from link
import numpy as np
from matplotlib import pyplot as plt
from scipy.cluster.hierarchy import dendrogram

from sklearn.cluster import AgglomerativeClustering
from sklearn.datasets import load_iris


def plot_dendrogram(model, **kwargs):
    # Create linkage matrix and then plot the dendrogram

    # create the counts of samples under each node
    counts = np.zeros(model.children_.shape[0])
    n_samples = len(model.labels_)
    for i, merge in enumerate(model.children_):
        current_count = 0
        for child_idx in merge:
            if child_idx < n_samples:
                current_count += 1  # leaf node
            else:
                current_count += counts[child_idx - n_samples]
        counts[i] = current_count

    linkage_matrix = np.column_stack(
        [model.children_, model.distances_, counts]
    ).astype(float)

    # Plot the corresponding dendrogram
    dendrogram(linkage_matrix, **kwargs)


iris = load_iris()
X = iris.data

# setting distance_threshold=0 ensures we compute the full tree.
model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)

model = model.fit(X)
plt.title("Hierarchical Clustering Dendrogram")
# plot the top three levels of the dendrogram
plot_dendrogram(model, truncate_mode="level", p=3)
plt.xlabel("Number of points in node (or index of point if no parenthesis).")
plt.show()


import numpy as np
from scipy.spatial.distance import pdist, squareform

# Define a set of objects
objects = np.array([[1, 10], [2, 11], [3, 4]])

# Calculate the pairwise distances
distances = pdist(objects)

# Convert the distances to a square matrix
distance_matrix = squareform(distances)


# Perform hierarchical clustering
Z = linkage(distance_matrix)

# Plot the dendrogram
plt.figure(figsize=(10, 5))
dendrogram(Z)
plt.show()








from scipy.cluster.hierarchy import linkage, dendrogram
from sklearn import metrics
import matplotlib.pyplot as plt
data = np.array([
    #0  1     2
    [1, 0.1, .25], # 0
    [0.1, 1, .8],  # 1
    [.25, .8, 1]   # 2
])
Z = linkage(data)
plt.figure()
dendrogram(Z, labels=np.array([0, 1, 2]))
plt.show()


import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
X, y = make_classification(random_state=0)
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    random_state=0)
clf = SVC(random_state=0)
clf.fit(X_train, y_train)
predictions = clf.predict(X_test)
cm = confusion_matrix(y_test, predictions, labels=clf.classes_)
print(cm)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                              display_labels=clf.classes_)
disp.plot()
plt.show()


import sys
import numpy as np
def DistanceMatrixPlotter(matrix: np.array):
    if type(matrix) != type(np.array([])):
        print("Error: please input a numpy array")
    n_dims = len(matrix.shape)
    if n_dims != 2:
        print("Error: the numpy array does not have 2 dimensions")
DistanceMatrixPlotter([1])


def tsv_array_converter(filepath):
    data = []
    with open(filepath, "r") as f:
        while True:
            line = f.readline()
            row = line.strip("\n").split("\t")
            if line:
                data.append(row)
            else:
                break

    labels = np.array(data[0][1:])
    data_dims = len(data) - 1
    data_array = np.zeros((data_dims, data_dims))
    for i in range(data_dims):
        for j in range(data_dims):
            try:
                data_array[i][j] = data[i+1][j+1]
            except ValueError:
                data_array[i][j] = 100.
    
    return data_array, labels

l, d = tsv_array_converter(os.path.join(os.getcwd(), "Generate_genetic_distance/mtDNA_genetic_distance.tsv"))
print(l)
print(d)


from sklearn.datasets import make_blobs
from sklearn.cluster import AgglomerativeClustering 
from scipy.spatial import distance_matrix
from scipy.cluster import hierarchy
from scipy.spatial.distance import squareform

X1, y1 = make_blobs(n_samples=50, centers=[[4,4],
                                           [-2, -1],
                                           [1, 1],
                                           [10,4]], cluster_std=0.9)
print(X1)




agglom = AgglomerativeClustering(n_clusters = 4, linkage = 'average')
agglom.fit(X1,y1)

dist_matrix = distance_matrix(X1,X1)
print(dist_matrix.shape)
condensed_dist_matrix = squareform(dist_matrix)
print(condensed_dist_matrix.shape)
Z = hierarchy.linkage(condensed_dist_matrix, 'complete')


M
