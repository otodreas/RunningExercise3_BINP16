





# Libraries
import sys
import os
import random
import pandas as pd
import numpy as np
from scipy.cluster.hierarchy import linkage, dendrogram
from scipy.spatial.distance import squareform
import matplotlib.pyplot as plt

random.seed(0)

















def is_probable_sequence(line):
    return all(ch in "ATCG?- " for ch in line.strip()) and len(line.strip()) > 0





def is_metadata_line(line):
    keywords = ["carrier", "patient", "not a", "hemophilia", "unknown"]
    low = line.lower() #convert to lower case
    return any(k in low for k in keywords) #match keyword to words in line in input file





def parse_genetic_data(input_file):
    mtDNA_dict = {}
    Y_dict = {}

    with open(input_file, 'r', encoding='utf-8', errors='ignore') as fh: #To read and clean file
        raw_lines = [ln.rstrip() for ln in fh.readlines()]

    lines = [] #clean the file to remove and replace certain characters and make it readable
    for ln in raw_lines:
        fixed = ln.replace("<92>", "'").replace("’", "'").strip()
        if fixed: #Removes empty lines
            lines.append(fixed)

    i = 0 #Current line index
    n = len(lines) #Total number of lines

    while i < n:
        line = lines[i].strip()

        if not line or is_metadata_line(line) or is_probable_sequence(line) or line.lower().startswith(("mtdna", "y chromosome")):
                #To skip blank or metadata lines
            i += 1
            continue

        person_name = line.lstrip('>').strip() #To detect person name and handle multi-line names

        #Merge consecutive name lines into one if they’re not DNA, metadata, or labels
        while (i + 1 < n and
               not is_probable_sequence(lines[i + 1]) and
               not is_metadata_line(lines[i + 1]) and
               not lines[i + 1].lower().startswith(("mtdna", "y chromosome"))):
            person_name += " " + lines[i + 1].strip()
            i += 1

        i += 1  #move past name line

        while i < n:
            current = lines[i].strip().lower()

            #mtDNA
            if current.startswith("mtdna"):
                if i + 1 < n and is_probable_sequence(lines[i + 1]): #reads next line - sequence
                    seq = lines[i + 1].replace(" ", "").upper()
                    mtDNA_dict[f"{person_name}_mtDNA"] = seq #saves the sequence with person name mtDNA
                    i += 2
                    continue
                else:
                    i += 1
                    continue

            #Y chromosome
            elif current.startswith("y chromosome") or current.startswith("ychr") or current == "y":
                if i + 1 < n and is_probable_sequence(lines[i + 1]): #reads next line - sequence
                    seq = lines[i + 1].replace(" ", "").upper()
                    Y_dict[f"{person_name}_Y"] = seq #saves the sequence with person name Y chromosome
                    i += 2
                    continue
                else:
                    i += 1
                    continue

            if (not is_probable_sequence(lines[i])
                and not lines[i].lower().startswith(("mtdna", "y chromosome"))
                and not is_metadata_line(lines[i])): #Break, if next line is a new name (not sequence or label)
                break

            i += 1

    return mtDNA_dict, Y_dict





def write_fasta(output_file, seq_dict): #To write a Fasta file
    with open(output_file, "w") as f:
        for name, seq in seq_dict.items():
            f.write(f">{name}\n{seq}\n")





def main():
    # Remove unwanted Colab/Jupyter args
    args = [arg for arg in sys.argv[1:] if not arg.startswith("-")]

    if len(args) < 2:
        input_file = input("Enter input file path (e.g. Input_Data/GeneticData.txt): ").strip()
        output_prefix = input("Enter output prefix (e.g. Output_Data/output): ").strip()
    else:
        input_file = args[0]
        output_prefix = args[1]

    # Input checks
    if not os.path.exists(input_file):
        print(f" Error: The input file '{input_file}' was not found.")
        sys.exit(1)

    # Parse file
    mtDNA_dict, Y_dict = parse_genetic_data(input_file)

    if not mtDNA_dict and not Y_dict:
        print(" No valid sequences found. Exiting.")
        sys.exit(0)

    # Create output files
    mt_output = f"{output_prefix}_mtDNA.fasta"  # f"Data/Outputs/Part_I/{output_prefix}_mtDNA.fasta"
    y_output = f"{output_prefix}_Y.fasta"

    write_fasta(mt_output, mtDNA_dict)
    write_fasta(y_output, Y_dict)

    print("\n Processing complete.")
    print(f"mtDNA → {mt_output}")
    print(f"Y chromosome → {y_output}")


if __name__ == "__main__":
    main()






# Library imports
import sys
import itertools





def read_fasta(fasta_file):
    seq_dict = {} #Initialize empty dictionary to store sequences
    with open(fasta_file, 'r') as f:
        header = None
        seq = []
        for line in f:
            line = line.strip()
            if not line: #To skip empty lines
                continue
            if line.startswith('>'):
                if header:
                    seq_dict[header] = ''.join(seq).upper() #Saves previous sequence
                header = line[1:].strip() #Stores new header
                seq = [] #resets sequence
            else:
                seq.append(line) #To handle multi-line sequences
        if header:
            seq_dict[header] = ''.join(seq).upper() #For the last sequence
    return seq_dict #returns a dictionary mapping sequence names to their aligned sequences





def default_weight_matrix(): #Default weights
    bases = ['A', 'T', 'C', 'G']
    weights = {}
    for b1 in bases:
        for b2 in bases:
            weights[(b1, b2)] = 2.0 if b1 == b2 else -1.0
    gap_open = -5
    gap_extend = -1
    # handle gaps and unknowns
    weights[('-', '-')] = 0.0
    weights[('?', '?')] = 0.0
    weights[('-', '?')] = 0.0
    weights[('?', '-')] = 0.0
    return weights





def read_weight_matrix(weight_file):
    weights = {} #initialize weights in this dictionary
    try:
        with open(weight_file, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("#"):
                    continue  # skip empty or comment lines

                parts = line.split()
                if len(parts) != 3:
                    print(f" Skipping malformed line in weight file: {line}")
                    continue

                base1, base2, value = parts
                try:
                    weights[(base1.upper(), base2.upper())] = float(value)
                except ValueError:
                    print(f" Invalid score value '{value}' in line: {line}")

        if not weights:
            print(" Warning: Weight file was empty or invalid. Using default weights.")
            weights = default_weight_matrix()

    except FileNotFoundError:
        print(f" Error: Weight file '{weight_file}' not found. Using default weights.")
        weights = default_weight_matrix()
    except Exception as e:
        print(f" Error reading weight matrix ({e}). Using default weights.")
        weights = default_weight_matrix()

    return weights





def pairwise_score(seq1, seq2, weight_matrix): #To calculate identity and alignment score for a pair of sequences
    assert len(seq1) == len(seq2) #Ensures sequences are same length (aligned)
    total_positions = len(seq1)
    identical = 0
    comparable = 0
    uncertain = 0
    score_sum = 0
    gap_open = -5
    gap_extend = -1
    in_gap = False
    for a, b in zip(seq1, seq2):
        if (a == '?' and b == '?') or (a == '?' and b == '-') or (a == '-' and b == '?') or (a == '-' and b == '-'): #Skips double gaps
            in_gap = False
            continue
        if (a == '?' and b in "ACGT") or (b == '?' and a in "ACGT"): #with one valid base and other uncertain base
            uncertain += 1
            in_gap = False
            continue
        if (a == '-' and b in "ACGT") or (b == '-' and a in "ACGT"): #with one valid base and an actual gap
            comparable += 1
            if not in_gap: #Entering a new gap
                score_sum += gap_open
                in_gap = True
            else:
                # Continuing the same gap
                score_sum += gap_extend
            score = weight_matrix.get((a, b)) #Gets score from weight matrix
            if score is None:
                score = weight_matrix.get((b, a), 0) #Use symmetry if score not found
            score_sum += score #Sum of alignment scores of all comparable positions
            continue
        if a in "ACGT" and b in "ACGT": #with both valid bases
            comparable += 1
            if a == b:
                identical += 1 #Counts positions where nucleotides match
            score = weight_matrix.get((a, b)) #Gets score from weight matrix
            if score is None:
                score = weight_matrix.get((b, a), 0) #Use symmetry if score not found
            score_sum += score #Sum of alignment scores of all comparable positions

    total_positions = comparable + uncertain
    if total_positions > 0:
        identity_percent = 100 * identical / total_positions #% of matching nucleotides over total length
    else:
        0
    return comparable, uncertain, total_positions, identity_percent, score_sum





def write_results(seq_dict, weight_matrix, output_file): #To write results in a text file
    headers = list(seq_dict.keys()) #Gets sequence names
    results = []

    for h1, h2 in itertools.combinations(headers, 2): #Generates all unique pairs of sequence
        seq1 = seq_dict[h1]
        seq2 = seq_dict[h2]
        comp, uncertain, total, identity, score = pairwise_score(seq1, seq2, weight_matrix)
        results.append((h1, h2, comp, uncertain, total, identity, score))

    with open(output_file, 'w') as out:
        out.write("SampleA | SampleB | Comparable nucleotides | uncertain nucleotides | Total nucleotides | IdentityScore | Score\n")
        for r in results:
            out.write(f"{r[0]} {r[1]} {r[2]} {r[3]} {r[4]} {r[5]:.1f}% {r[6]}\n")

    print(f"Results written to {output_file}")





def main():
    args = [arg for arg in sys.argv[1:] if not arg.startswith("-")]

    if len(args) < 4:
        print(" No valid command-line arguments detected.")
        mtDNA_file = input("Enter path to mtDNA FASTA file: ").strip()
        Y_file = input("Enter path to Y chromosome FASTA file: ").strip()
        weight_file = input("Enter path to weight parameters file (or leave blank for default): ").strip()
        output_prefix = input("Enter output prefix (e.g. results): ").strip()
    else:
        mtDNA_file = args[0]
        Y_file = args[1]
        weight_file = args[2]
        output_prefix = args[3]

    # Validate input files
    for f in [mtDNA_file, Y_file]:
        if not os.path.exists(f):
            print(f" Error: Input file '{f}' not found.")
            sys.exit(1)

    # Load weight matrix
    if weight_file and os.path.exists(weight_file):
        try:
            weight_matrix = read_weight_matrix(weight_file)
            print(f" Loaded weight matrix from {weight_file}")
        except Exception as e:
            print(f" Error reading weight file ({e}). Using default weights.")
            weight_matrix = default_weight_matrix()
    else:
        print(" No valid weight file provided. Using default weights.")
        weight_matrix = default_weight_matrix()

    # Process mtDNA
    try:
        mtDNA_dict = read_fasta(mtDNA_file)
        mtDNA_output = f"{output_prefix}_mtDNA_scores.txt"
        write_results(mtDNA_dict, weight_matrix, mtDNA_output)
        print(f" mtDNA alignment results saved to: {mtDNA_output}")
    except Exception as e:
        print(f" Error processing mtDNA file: {e}")

    # Process Y chromosome
    try:
        Y_dict = read_fasta(Y_file)
        Y_output = f"{output_prefix}_Y_scores.txt"
        write_results(Y_dict, weight_matrix, Y_output)
        print(f" Y chromosome alignment results saved to: {Y_output}")
    except Exception as e:
        print(f" Error processing Y chromosome file: {e}")

    # Print summary
    print("\n Processing complete.")
    print(f"Weight parameters used: {weight_matrix}")

if __name__ == "__main__":
    main()


















# process MSA data, build dataframe
def load_MSA(input_file):
    rows = []
    try:
        with open(input_file, "r") as f:
            next(f)  # skip header
            for line in f:
                parts = line.strip().split()
                if len(parts) < 6:
                    print(f"Warning: Skipping malformed line: {line}")
                    continue

                # Extract sample names
                try:
                    for i, p in enumerate(parts):
                        if "_" in p:
                            SampleA_idx = i
                            SampleA = " ".join(parts[0 : SampleA_idx + 1])
                            break
                    for j in range(SampleA_idx + 1, len(parts)):
                        if "_" in parts[j]:
                            SampleB_idx = j
                            SampleB = " ".join(parts[SampleA_idx + 1 : SampleB_idx + 1])
                            break

                    numeric_parts = parts[SampleB_idx + 1 :]
                    comparable = int(numeric_parts[0])
                    uncertain = int(numeric_parts[1])
                    total = int(numeric_parts[2])
                    identity = float(numeric_parts[3].rstrip("%"))
                    score = float(numeric_parts[4])

                    rows.append(
                        [SampleA, SampleB, comparable, uncertain, total, identity, score]
                    )
                except Exception as e:
                    print(f"Warning: Skipping line due to parse error: {line}\nError: {e}")
                    continue

        df = pd.DataFrame(
            rows,
            columns=[
                "SampleA",
                "SampleB",
                "Comparable nucleotides",
                "uncertain nucleotides",
                "Total nucleotides",
                "IdentityScore",
                "Score",
            ],
        )
        return df

    except FileNotFoundError:
        sys.exit(f"Error: Input file '{input_file}' not found.")
    except Exception as e:
        sys.exit(f"Error: Failed to load MSA file. Details: {e}")





def calculate_identity_similarity(input_df):
    # Identity score correction (optional)
    err = 0.1
    # Remove the percent sign from the identity score and convert it to a decimal
    input_df["IdentityScore"] = input_df["IdentityScore"].astype(float) / 100
    # The adjusted identity score (IdentityScore_tr) is computed by reducing the original identity score by
    # a fraction proportional to the error rate, and adding back a compensation term based on the remaining non-identity portion.
    # Specifically, we subtract IdentityScore * err from the original value and add (1 - IdentityScore) * err.
    input_df["IdentityScore_tr"] = (
        input_df["IdentityScore"]
        - input_df["IdentityScore"] * err
        + (1 - input_df["IdentityScore"]) * err
    )

    input_df["genetic_distance_identity"] = 1 - input_df["IdentityScore_tr"]
    clean_df = input_df[["SampleA", "SampleB", "genetic_distance_identity"]]

    return clean_df





def calculate_alignment_similarity(input_df):
    # Calculate genetic distance by alignment score
    # TODO: calculate average alignment score per comparable bases
    # TODO: normalize the alignment score
    input_df["ave_alignment_score"] = (
        input_df["Score"] / input_df["Comparable nucleotides"]
    )
    score_min = input_df["ave_alignment_score"].min()
    score_max = input_df["ave_alignment_score"].max()
    input_df["similarity"] = (input_df["ave_alignment_score"] - score_min) / (
        score_max - score_min
    )  # NOTE:(optional) clip the extreme 0 and 1 for pairs with max and min values

    input_df["genetic_distance_alignment"] = 1 - input_df["similarity"]
    clean_df = input_df[["SampleA", "SampleB", "genetic_distance_alignment"]]

    return clean_df





def create_matrix(input_df):
    try:
        # Construct the final genetic distance matrix
        labels = pd.concat(
            [input_df["SampleA"], input_df["SampleB"]]
        ).unique()  # Extrac all elements in data

        gd_df = pd.DataFrame(
            ".", index=labels, columns=labels
        )  # create an empty dataframe to store genetic distances

        # fill the matrix
        for idx, row in input_df.iterrows():
            s1 = row["SampleA"]
            s2 = row["SampleB"]
            if "genetic_distance_identity" in input_df.columns:
                s3 = row["genetic_distance_identity"]
            else:
                s3 = row["genetic_distance_alignment"]
            # optional: Keep s3 to three decimal places
            # s3 = round(s3, 3)

            gd_df.at[s1, s2] = s3
            gd_df.at[s2, s1] = s3

        return gd_df
    except KeyError as e:
        sys.exit(f"Error: Missing expected column in dataframe: {e}")
    except Exception as e:
        sys.exit(f"Error: Failed to create genetic distance matrix. Details: {e}")

def ensure_tsv(filename):
    if not filename.lower().endswith(".tsv"):
        filename += ".tsv"
    return filename








input_file_name = input("Please enter the input file name(results_mtDNA_scores.txt or results_Y_scores.txt)：")  # TODO: what input file???
output_id_name = input("Please enter the name to generate identity score matrix (or leave blank for default)：")
output_align_name = input("Please enter the name to generate alignment score matrix (or leave blank for default):")
sys.argv = ["notebook", input_file_name, output_id_name, output_align_name]


# Access arguments passed from the command line written in the terminal
# check we have 4 arguements: the python script, input file, output_identity_matrix and output_alignment_matrix
def main():
    if len(sys.argv) < 2:
        sys.exit("Error: You must provide the input file as the first argument.")
    input_file = sys.argv[1]

    base_name = os.path.splitext(os.path.basename(input_file))[0]
    output_identity_matrix = sys.argv[2] if len(sys.argv) > 2 and sys.argv[2].strip() else f"{base_name}_identity_matrix.tsv"
    output_alignment_matrix = sys.argv[3] if len(sys.argv) > 3 and sys.argv[3].strip() else f"{base_name}_alignment_matrix.tsv"

    print(f"Input file: {input_file}")
    print(f"Identity matrix: {output_identity_matrix}")
    print(f"Alignment matrix: {output_alignment_matrix}")

    # open and read input file
    # Confirm the data type of the input file
    df = load_MSA(input_file)
    out_identity_matrix = calculate_identity_similarity(df)
    out_alignment_matrix = calculate_alignment_similarity(df)

    gd_identity_df = create_matrix(out_identity_matrix)
    gd_alignment_df = create_matrix(out_alignment_matrix)

    # Write the matrix to the output file
    output_identity_matrix = ensure_tsv(output_identity_matrix)
    try:
        gd_identity_df.to_csv(output_identity_matrix, sep="\t", index=True)
        saved_identity_path = os.path.abspath(output_identity_matrix)
        print(f"Identity matrix saved to: {saved_identity_path}")
    except Exception as e:
        sys.exit(f"Error saving identity matrix: {e}")

    output_alignment_matrix = ensure_tsv(output_alignment_matrix)
    try:
        gd_alignment_df.to_csv(output_alignment_matrix, sep="\t", index=True)
        saved_alignment_path = os.path.abspath(output_alignment_matrix)
        print(f"Alignment matrix saved to: {saved_alignment_path}")
    except Exception as e:
        sys.exit(f"Error saving alignment matrix: {e}")


    print("Finish")


if __name__ == "__main__":
    main()














# Store name and description information
name_library_dict = {'Princess Irene': 'princess Anastasia\' aunt',
                    'Prince Fred': 'princess Anastasia\' uncle',
                    'Nicolas II Romanov': 'princess Anastasia\' father',
                    'Alexandra Romanov': 'princess Anastasia\' mother',
                    'Olga Romanov': 'princess Anastasia\' sister',
                    'Tatiana Romanov': 'princess Anastasia\' sister',
                    'Maria Romanov': 'princess Anastasia\' sister',
                    'Alexei Romanov': 'princess Anastasia\' brother',
                    'Suspected body of Anastasia Romanov': 'the body of princess Anastasia?',
                    'Anastasia1': 'the candidate1 for princess Anastasia',
                    'Anastasia2': 'the candidate2 for princess Anastasia',
                    'Anastasia3': 'the candidate3 for princess Anastasia',
                    'Anastasia4 son': 'the son of the candidate4 for princess Anastasia',
                    'Anastasia5': 'the candidate5 for princess Anastasia',
                    'Farmers grandson': 'the grandson of a farmer, who admitted to having witnessed the murder',
                    'Grigori Rasputin': 'a Russian peasant and a questionable doctor who spent much time drinking'}


def name_library(name_mode):
    if name_mode == "ALL":
        print("You have choose to see the mystery of the whole ROMANOV family\n")
        return
    if name_mode in name_library_dict:
        description = name_library_dict.get(name_mode)
        print(f"Great! You choose {name_mode}. This is {description}\n")
    else:
        print("Wrong input! Try again.\n")





# ask users to decide which data to show in the output
def print_mode(score_mode):
    if score_mode == "identity":
        return 'IdentityScore'
    elif score_mode == "alignment":
        return 'Score'
    else:
        print("Wrong input!  Type 'identity' or 'alignment'")

# if only a name in query, make sure it's in the 1st column in output data
def put_name_first(df_file, name):
    df_new = df_file.copy()
    for idx, row in df_new.iterrows():
        if row['SampleB'] == name:
            df_new.at[idx, 'SampleA'], df_new.at[idx, 'SampleB'] = row['SampleB'], row['SampleA']

    return df_new


# process single name
def process_name(df_file, name, col3):
    # extract the line with query name, and the largest IdentityScore
    subset = df_file[(df_file['SampleA'] == name) | (df_file['SampleB'] == name)]
    max_val = subset[col3].max()
    filered_line = subset[subset[col3] == max_val]
    sorted_line = put_name_first(filered_line, name)
    usr_output = pd.DataFrame(sorted_line, columns=['SampleA', 'SampleB', col3])  # Create DataFrame
    return usr_output

# process ALL
def process_all(df_file, col3):
    usr_output = df_file[['SampleA', 'SampleB', col3]]
    return usr_output









input_file_name = input("Please enter the input file name: ").strip()
name_mode = input("Please enter the name to analyze (or 'ALL')").strip()
output_file = input("Please enter the output file name (leave blank for default): ").strip()
sys.argv = ["notebook", input_file_name, name_mode, output_file]


def main():
    if len(sys.argv) < 3:  # Validate command-line arguments
        print("Usage: script.py <input> [output_file]")
        sys.exit(1)
    else:
        input_file = sys.argv[1]
        name_mode = sys.argv[2]
        output_file = sys.argv[3] if len(sys.argv) == 4 else None

    # print promopts
    print("Welcome to the mystery of ROMANOV family\n")
    print("♡ ✧*｡♡ ✧*｡♡ ✧*｡♡ ✧*｡♡ ✧*｡♡ ✧*｡\n ")

    # check if the name is valid
    valid_names = list(name_library_dict.keys())

    if name_mode.strip().lower() == "all":
        name_mode = "ALL"
    elif name_mode not in valid_names:
        print(f"\nERROR: The name '{name_mode}' is not in the dataset!")
        print("Please enter one of the following names, or 'ALL':\n")
        print(f"{valid_names}")
        sys.exit(1)

    name_library(name_mode)

    filename_only = os.path.basename(input_file)

    # determine if the name is in data (gender)
    male = ['Prince Fred', 'Nicolas II Romanov', 'Alexei Romanov', 'Anastasia4 son',
            'Farmers grandson', 'Grigori Rasputin' ]

    if 'mtdna' in filename_only.lower():
        print("You are checking the mtDNA similarity")
    else:
        print("You are checking the YDNA data")
        if name_mode != 'ALL' and name_mode not in male:
            print("\nWARNING: The name you type is female: no YDNA data avaliable!")
            print(f"reference:{male}\n")
            sys.exit(1)

    print("============================================\n")
    score_mode = input("Type 'identity' or 'alignment':\n").strip().lower()
    if score_mode not in ["identity", "alignment"]:
        print("Invalid input! Please type 'identity' or 'alignment'")
        sys.exit()

    try:
        gd_df = load_MSA(input_file)  # convert txt.format input into df format
    except Exception as e:
        sys.exit(f"Error loading input file: {e}")

    # remove the '_mtDNA' and 'ydna' suffix after people names
    try:
        gd_df['SampleA'] = gd_df['SampleA'].str.replace(r'_mtDNA|_Y','',regex=True)
        gd_df['SampleB'] = gd_df['SampleB'].str.replace(r'_mtDNA|_Y','',regex=True)
    except Exception as e:
        sys.exit(f"Error processing sample names: {e}")

    col3 = print_mode(score_mode)

    ## process data
    if name_mode == 'ALL':
        result = process_all(gd_df, col3)
    else:
        result = process_name(gd_df, name_mode, col3)

    if score_mode == 'identity':  # if user choose identity score, add back '%'
        result = result.copy()
        result[col3] = result[col3].astype(str) + '%'

    print("============================================\n")
    if output_file:
        result.to_csv(output_file, sep="\t", index=False)
        saved_path = os.path.abspath(output_file)
    else:  # if no output_file, save default name
        default_file = "similarity_output.tsv"
        print("\nSince you didn't set the output file name, it created as default 'similarity_output.tsv'")
        result.to_csv(default_file, sep="\t", index=False)
        saved_path = os.path.abspath(default_file)
    print(f"\nYour output file is saved at {saved_path}\nGo and check! ๐•ᴗ•๐")


if __name__ == "__main__":
    main()








# User inputs
input_file = "/content/GeneticData_-_4.txt"
chromo_name = "mtDNAx"
output_file = "output_file.tsv"


# Input handling

# Set user-assigned variables
if not output_file.endswith(".tsv"):
      sys.exit("The output file path must be a .tsv file.")
# Check that input_file exists
if not os.path.isfile(input_file):
    sys.exit("Input file does not exist")

# Get valid chromosome names from the user
valid_chromo_names = ["mtDNA", "Y_chromosome"]

while chromo_name not in valid_chromo_names:
    chromo_name = input(
        f"Invalid chromosome name. Please enter one of the following chromosome names: {valid_chromo_names}, or 'abort' to exit: "
    )
    if chromo_name.lower() == "abort":
        sys.exit("Program aborted.")

# Replace "_" with " " to match data
chromo_name = chromo_name.replace("_", " ")


# Custom functions

def read_chromosomes(input_file, chromo_name):
    # Open input file as binary
    with open(input_file, "rb") as f:
        # Assign variables
        chromo_line = None
        i = 0
        seqs = []

        # Read lines to strings. Clean and append lines after chromosome header to data.
        while True:
            line_b = f.readline()
            line = str(line_b)

            # The chromosome data will be on the line following the chromosome name.
            if chromo_name in line:
                chromo_line = i + 1
            if i == chromo_line:
                clean_line = line[
                    2 : line.find("\\")
                ]  # since files are read in binary, the first two characters will always be 'b.
                seqs.append(clean_line)
            i += 1
            if not line_b:
                break

        return seqs


# Program logic
seqs = read_chromosomes(input_file, chromo_name)

# Check that at least one sequence was found
if len(seqs) < 3:
    sys.exit(
        f"Error: too few (<3) chromosomes of '{chromo_name}' found. File corrupted?"
    )

# Get the lengths of each sequence, check that they are equal, assign it to the variable positions.
seq_lens = []
for seq in seqs:
    seq_lens.append(len(seq))
if len(set(seq_lens)) > 1:
    sys.exit(f"Error: sequences for '{chromo_name}' have different lengths.")
else:
    positions = seq_lens[0]


### Perform calculations and write data ###

# Assign variables
header = [
    "Chromosome",
    "Position",
    "Alleles",
    "Major Allele",
    "Minor Allele",
    "Minor Allele Frequency",
]
row_written = False
total_positions = positions * len(seqs)
total_nucleotides = 0

# Loop through positions
for p in range(positions):
    # Assign empty list to nucleotides, where valid nucleotides at position p will be stored.
    nucleotides = []

    # Loop through sequences
    for seq in seqs:
        # Append nucleotide list nucleotides
        if seq[p].upper() in "ACGT":
            nucleotides.append(seq[p].upper())

    # Throw warning if no valid nucleotides were found at position p.
    if len(nucleotides) == 0:
        print(f"Warning: no valid nucleotides found at position {p + 1}")

    # If multiple different nucleotides were found at the position, calculate statistics.
    elif nucleotides.count(nucleotides[0]) < len(nucleotides):
        # get unique nucleotides.
        alleles = set(nucleotides)

        # Store nucleotide frequencies by allele in the dictionary freqs.
        freqs = {}
        for allele in alleles:
            freqs[allele] = nucleotides.count(allele)

        # Since alleles is a set, sort the dictionary for reproducibility
        freqs = dict(sorted(freqs.items()))

        # Find major alleles, minor alleles, and minor frequency of alleles.
        # Ensure random selection if multiple major or minor alleles have the same frequency.
        major_alleles = []
        minor_alleles = []
        for allele in freqs.keys():
            if freqs[allele] == max(list(freqs.values())):
                major_alleles.append(allele)
            if freqs[allele] == min(list(freqs.values())):
                minor_alleles.append(allele)
        major_allele = random.choice(major_alleles)

        if major_allele in minor_alleles:
            minor_alleles.pop(
                minor_alleles.index(major_allele)
            )  # when all allele frequencies are equal, ensure the same allele cannot be both major and minor.
        minor_allele = random.choice(minor_alleles)
        minor_allele_freq = freqs[minor_allele] / sum(
            freqs[allele] for allele in alleles
        )
        row = (
            "\t".join(
                [
                    chromo_name,
                    str(p),
                    "/".join(alleles),
                    str(major_allele),
                    str(minor_allele),
                    str(round(minor_allele_freq, 2)),
                ]
            )
            + "\n"
        )

        # Update total_nucleotides
        total_nucleotides += sum(freqs.values())

        # Write output file, including the header if writing the first row.
        if not row_written:
            with open(output_file, "w") as f:
                header_row = "\t".join(header) + "\n" + row
                f.write(header_row)

                # Print data for inspection and update row_written to avoid re-writing the header.
                print(header_row.strip())
                row_written = True
        else:
            with open(output_file, "a") as f:
                f.write(row)

                # Print data for inspection.
                print(row.strip())

# Print location of saved file.
print(f"Output saved to {os.path.join(os.getcwd(), output_file)}")

# Warn the user of low-quality data if less than 25% of positions contain valid nucleotides
pct_nucleotides = total_nucleotides / total_positions
if pct_nucleotides < 0.25:
    print(
        f"Warning: {round(pct_nucleotides * 100, 2)}% of positions in the dataset contain valid nucleotides"
    )





# User inputs

# pass a list containing <= 4 file names or a list containing 1 directory to manual_input_files
manual_input_files = [
    "/content/outmatrix_Y_alignment.tsv",
    "/content/outmatrix_Y_identity.tsv",
    "/content/outmatrix_mtDNA_alignment.tsv",
    "/content/outmatrix_mtDNA_identity.tsv"
    ]



# Input handling

# Set user-assigned variables
if len(manual_input_files) > 4:
    sys.exis("Too many arguments. Please pass at most four input files.")

# One argument passed:
elif len(manual_input_files) < 2:
    # Check if the sole argument is a directory.
    if os.path.isdir(manual_input_files[0]):
        # Get .tsv files
        tsv_files = [f for f in os.listdir(manual_input_files[0]) if f.endswith(".tsv")]

        # Check that the directory contains no more than 4 .tsv files.
        if len(tsv_files) <= 4:
            # Create empty list input_files to store filepaths in.
            input_files = [""] * len(tsv_files)
            # Loop through the filepaths in the directory passed and add them to input_files
            for i, f in enumerate(tsv_files):
                input_files[i] = os.path.join(manual_input_files[0], f)
        else:
            sys.exit(f"Too many files in {manual_input_files[0]}")
    # One file was passed to the program:
    else:
        input_files = manual_input_files

# Multiple files were passed:
else:
    input_files = [""] * len(manual_input_files)
    for i in range(len(input_files)):
        input_files[i] = manual_input_files[i]

# Loop through input_files and check for invalid files.
for f in input_files:
    nonexistent_files = []
    nontsv_files = []
    if not os.path.isfile(f):
        nonexistent_files.append(f)

    # Check that input_file is a .tsv file:
    if not f.endswith(".tsv"):
        nontsv_files.append(f)

# Print errors.
if len(nonexistent_files) > 0:
    sys.exit(
        f"The following files do not exist or are directories: {nonexistent_files}"
    )
if len(nontsv_files) > 0:
    sys.exit(f"The following files are not tsv files: {nontsv_files}")


# Custom functions and classes

# User can type "Abort" at any time and abort the program.
def abort(user_input):
    if user_input.lower() == "abort" or user_input.lower() == "exit":
        sys.exit("Program aborted.")
    else:
        return user_input


# Class for list of input files.
class Matrix_Files_Metadata:
    def __init__(self, input_files):
        self.input_files = input_files

    # When printing, return input_files
    def __str__(self):
        return str(self.input_files)

    # Getting metadata (chromosome counts, metric counts)
    def get_metadata(self):
        # user input interface
        chromosomes = []
        metrics = []
        metadata = [chromosomes, metrics]
        metadata_input_tags = ["CHROMOSOME", "METRIC"]

        # Loop through files.
        for input_file in self.input_files:
            # Loop through chromosomes and metrics
            for j, tags in enumerate(metadata):
                # Get tag name from user if none have been passed (force input since you cannot iterate through empty list)
                if len(tags) == 0:
                    tags.append(
                        abort(
                            input(
                                f"Please input the {metadata_input_tags[j]} name in the file '{input_file}': "
                            )
                        )
                    )
                # If tags list contains at least 1 entry:
                else:
                    tag_already_labeled = False
                    # Loop through tags
                    for tag in tags:
                        # If tag is already represented in input file, update tag_already_labeled
                        if tag in input_file:
                            tag_already_labeled = True
                    if tag_already_labeled:
                        pass
                    # Prompt user to input tag if it is not represented in list of tags
                    else:
                        tags.append(
                            abort(
                                input(
                                    f"Please input the {metadata_input_tags[j]} name in the file '{input_file}': "
                                )
                            )
                        )

            # Generate dictionaries to return
            chromo_counts = {}
            metric_counts = {}

            # Loop through chromosomes and metrics, initializing dictionaries with 0
            for c in chromosomes:
                chromo_counts[c] = 0
            for m in metrics:
                metric_counts[m] = 0

            # Loop through input files and get the number of occurrences of metadata
            for input_file in self.input_files:
                for c in chromosomes:
                    if c in input_file:
                        chromo_counts[c] += 1
                for m in metrics:
                    if m in input_file:
                        metric_counts[m] += 1

        return (chromo_counts, metric_counts)


# Create object class Matrix_File for each file.
class Matrix_File:
    def __init__(self, filepath):
        self.filepath = filepath

    # Get the chromosome and metric for each file
    def get_name(self, chromosomes, metrics):
        """
        Get the chromosome and metric names for a Matrix_File
        given the dictionaries 'chromosomes' and 'metrics' containing
        counts of each category of metadata in a Matrix_File_Metadata
        object.
        """

        chromosome = []
        metric = []

        # Loop through dictionary keys and grab the correct key
        for c in chromosomes.keys():
            if c in self.filepath:
                chromosome.append(c)
        for m in metrics.keys():
            if m in self.filepath:
                metric.append(m)

        # Check that the file contains exactly one entry of each metadata type.
        if len(chromosome) + len(metric) != 2:
            sys.exit(
                f"File {self.filepath} does not contain exactly one chromosome and one metric name."
            )
        else:
            # Convert metadata from list to string if it passes the check above.
            chromosome = "".join(chromosome)
            metric = "".join(metric)

        self.chromosome = chromosome
        self.metric = metric

        return chromosome, metric

    def get_data(self):
        """
        Extract numerical and categorical data from .tsv file of type Matrix_File.
        Return data in separate numpy arrays. Replace missing numerical values with 0.
        """
        # Open filepath associated with object and store lines as lists in list data
        data = []
        with open(self.filepath, "r") as f:
            while True:
                line = f.readline()
                row = line.strip("\n").split("\t")
                if line:
                    data.append(row)
                else:
                    break

        # Ensure that there are at least 2 columns and that every row has the same number of columns
        row_lengths = {len(row) for row in data}
        if len(row_lengths) > 1 or row_lengths == {1}:
            sys.exit(f"Delimiter issues. Rows read have length(s) {row_lengths}")

        # Set labels variable to the headers of the input file, not including the first empty value
        labels = np.array(data[0][1:])

        # data_dims is assigned to the length of the input data, not including the categorical headers
        data_dims = len(data) - 1

        # create an array of zeroes with dimensions of the input data
        data_array = np.zeros((data_dims, data_dims))
        data_array_debug = np.copy(data_array)

        # Loop through columns of numerical data
        for i in range(data_dims):
            # Check that the vertical label matches the horizontal label. An "upside-down" matrix will not pass.
            if data[i + 1][0] != labels[i]:
                sys.exit("Matrix axes are unaligned. Perhaps the Y axis is inverted?")
            # Loop through rows of numerical data
            non_diagonal_zeros = 0
            for j in range(data_dims):
                # Update value if the input value is numerical
                try:
                    data_array[i][j] = data[i + 1][
                        j + 1
                    ]  # account for the header rows by increasing indecies by 1.
                    # Diagonals must have a score of 0.
                    if data_array[i][j] > 0 and i == j:
                        sys.exit(
                            f"The identity matrix {self.filepath} does not contain a 0 value at diagonal position {i + 1, j + 1}"
                        )

                # Non numerical value handling
                except ValueError:
                    # The only acceptable non-numerical value is "." and "".
                    if data[i + 1][j + 1] != "." and data[i + 1][j + 1] != "":
                        sys.exit(
                            f"The identity matrix {self.filepath} contains the non-numerical value '{data[i + 1][j + 1]}' at position {i + 1, j + 1}"
                        )
                    # Warn the user when non-diagonals have a score of 0. Limit the number of 0 values to 25% of the matrix.
                    if i != j:
                        non_diagonal_zeros += 1
                        if non_diagonal_zeros > data_dims * data_dims / 4:
                            sys.exit(
                                f"The identity matrix {self.filepath} contains more than 25% empty values."
                            )
                        print(
                            f"Warning: the identity matrix {self.filepath} contains an empty value at non-diagonal position {i + 1, j + 1}"
                        )
                    pass  # leave non-numerical values in the diagonal as 0.

        # Access the chromosome of the Matrix_File
        chromosome_tag = self.chromosome

        # Loop through labels, removing chromosome tags if labels are delimited with "_".
        for i, label in enumerate(labels):
            if "_" in label:
                label_terms = label.split("_")
                label_terms_lower = label.lower().split("_")
                while chromosome_tag not in label_terms:
                    chromosome_tag = str(
                        abort(
                            input(
                                f"The matrix row/column labels do not match the chromosome tag '{chromosome_tag}' in the file name '{self.filepath}'. "
                                f"From the matrix data label '{label}', what characters represent the chromosome name? "
                            )
                        )
                    )

                label_terms.pop(label_terms.index(chromosome_tag))
                label_trim = "_".join(label_terms)
                labels[i] = label_trim

        return data_array, labels


# Define function to create dendrogram plots with multiple input files
def custom_dendrogram(input_files, figure_number):
    # Set subplots based on input files passed
    fig, axs = plt.subplots(
        1, len(input_files), figsize=(10 + 5 * (len(input_files) - 1), 5)
    )

    # create blank metrics list to store metrics in to present in figure legend
    metrics = []

    # Initialize orientations and orientation flipper to mirror plots
    orientations = ["left", "right"]
    orientation_flipper = 0
    # Loop through input files, creating subplots
    for i, input_file in enumerate(input_files):
        # Handle single inputs, when axes objects are not iterable
        ax = axs[i] if len(input_files) > 1 else axs

        # Get custom attributes from input file
        fileobject = Matrix_File(input_file)
        chromosome, metric = fileobject.get_name(chromo_counts, metric_counts)
        data, labels = fileobject.get_data()

        # Flatten 2D input matrix to 1D without updating values using squareform
        c_data = squareform(data)
        # Calculate pairwise euclidean distances between points using the nearest point algorithm
        Z = linkage(c_data)
        # Create dendrogram, update flipper
        dendrogram(
            Z, orientation=orientations[orientation_flipper], labels=labels, ax=ax
        )
        orientation_flipper = not orientation_flipper

        # Color labels by family
        romanovs = np.array(
            ["Romanov", "Olga", "Tatiana", "Marie", "Anastasia", "Alexandra", "Nicolas"]
        )
        # Loop through y tick labels, assign colors
        for j, plot_label in enumerate(ax.get_yticklabels()):
            for k, romanov in enumerate(romanovs):
                # If the label matches any entry in the array romanovs, set the label to blue.
                if romanov.lower() in plot_label.get_text().lower():
                    plot_label.set_color("blue")
                    break
                elif k < len(romanovs) - 1:
                    pass
                # If all romanov names have been checked, set the label to red.
                else:
                    plot_label.set_color("red")

        metrics.append(metric)

    # Set the legend of the full plot and save.
    legend = f"Hierarchical clustering of genetic distances (algorithm: nearest point).\nChromosome: {chromosome}. Metric(s) (from left): {', '.join(metrics)}"
    plt.tight_layout()
    plt.show()
    print(f"Figure {figure_number}: {legend}")
    plt.savefig(f"dendrogram_{chromosome}.png")


# Define function to create heatplots with multiple input files
def custom_heatmap(input_files, figure_number):
    # Set subplots based on input files passed
    fig, axs = plt.subplots(
        1, len(input_files), figsize=(5 + 5 * (len(input_files) - 1), 5)
    )

    # create blank metrics list to store metrics in to present in figure legend
    metrics = []

    # Loop through input files, creating subplots
    for i, input_file in enumerate(input_files):
        # Handle single inputs, when axes objects are not iterable
        ax = axs[i] if len(input_files) > 1 else axs

        # Get custom attributes from input file
        fileobject = Matrix_File(input_file)
        chromosome, metric = fileobject.get_name(chromo_counts, metric_counts)
        data, labels = fileobject.get_data()

        # Trim labels if they are too long
        max_char_len = 18
        for j, label in enumerate(labels):
            if len(label) > max_char_len:
                labels[j] = "".join(["...", label[len(label) - max_char_len :]])

        # Flip sign of data so that more closely related pairs have higher values
        data = np.negative(data)
        # Plot image
        im = ax.imshow(data, cmap="nipy_spectral")
        cbar = ax.figure.colorbar(im)

        # Update tick labels
        xticks, yticks = list(labels), list(labels)
        ax.set_xticks(range(len(labels)), xticks, rotation=90)
        ax.set_yticks(range(len(labels)), yticks)
        metrics.append(metric)


    # Set legend and save
    legend = f"Negative genetic distance heatmap.\nChromosome: {chromosome}. Metric(s) (from left): {', '.join(metrics)}"
    fig.tight_layout()
    plt.show()
    print(f"Figure {figure_number}: {legend}")
    plt.savefig(f"heatmap_{chromosome}.png")


# Program logic

# Get metadata
input_files_metadata = Matrix_Files_Metadata(input_files)
chromo_counts, metric_counts = input_files_metadata.get_metadata()

# Loop through chromosomes, plotting data that share chromosomes
for i, chromosome in enumerate(chromo_counts.keys()):
    chromo_input_files = []
    for input_file in input_files:
        if chromosome in input_file:
            chromo_input_files.append(input_file)

    custom_dendrogram(chromo_input_files, figure_number=(i * 2 + 1))
    custom_heatmap(chromo_input_files, figure_number=(i * 2 + 2))






